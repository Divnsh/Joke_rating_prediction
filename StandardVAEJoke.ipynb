{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StandardVAEJoke.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8J1As92RIKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "train_mat=pickle.load(open(\"train_mat.file\", \"rb\" ) )\n",
        "val_mat=pickle.load(open(\"val_mat.file\", \"rb\" ) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_Gz8HvIP1CF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from keras.layers import Input, Dense, Lambda\n",
        "from keras.models import Model\n",
        "from keras import objectives\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, Callback\n",
        "from IPython.display import clear_output\n",
        "\n",
        "\n",
        "# encoder/decoder network size\n",
        "batch_size=162\n",
        "original_dim=train_mat.shape[1] # number of jokes\n",
        "intermediate_dim=int(train_mat.shape[1]*0.6)\n",
        "latent_dim=int(train_mat.shape[1]*0.2)\n",
        "nb_epochs=20\n",
        "epsilon_std=1.0\n",
        "\n",
        "# encoder network\n",
        "x=Input(batch_shape=(batch_size,original_dim))\n",
        "h=Dense(intermediate_dim, activation='tanh')(x)\n",
        "z_mean=Dense(latent_dim)(h)\n",
        "z_log_var=Dense(latent_dim)(h)\n",
        "\n",
        "\n",
        "# sampling from latent dimension for decoder/generative part of network\n",
        "def sampling(args):\n",
        "    _mean,_log_var=args\n",
        "    epsilon=K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0., stddev=epsilon_std)\n",
        "    return _mean+K.exp(_log_var/2)*epsilon\n",
        "\n",
        "z= Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
        "\n",
        "# decoder network\n",
        "h_decoder=Dense(intermediate_dim, activation='tanh')\n",
        "x_bar=Dense(original_dim,activation='linear') # this should be linear right?\n",
        "h_decoded = h_decoder(z)\n",
        "x_decoded = x_bar(h_decoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4-t_CQKQIZ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train=train_mat\n",
        "x_val = val_mat.todense()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rd9-IqP9QI3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Standard VAE recommender\n",
        "\n",
        "\n",
        "class PlotLosses(Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.i = 0\n",
        "        self.x = []\n",
        "        self.losses = []\n",
        "        self.val_losses = []\n",
        "        \n",
        "        self.fig = plt.figure()\n",
        "        \n",
        "        self.logs = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        \n",
        "        self.logs.append(logs)\n",
        "        self.x.append(self.i)\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.val_losses.append(logs.get('val_loss'))\n",
        "        self.i += 1\n",
        "        \n",
        "        clear_output(wait=True)\n",
        "        plt.plot(self.x, self.losses, label=\"loss\")\n",
        "        plt.plot(self.x, self.val_losses, label=\"val_loss\")\n",
        "        plt.legend()\n",
        "        plt.show();\n",
        "        \n",
        "plot_losses = PlotLosses()\n",
        "\n",
        "\n",
        "# build and compile model\n",
        "vae = Model(x, x_decoded)\n",
        "def vae_loss(x,x_bar):\n",
        "    mask = tf.greater_equal(x, -10) # Masking values corresponding to missing items for each user\n",
        "    indexes = tf.where(mask)\n",
        "    reconst_loss=tf.reduce_mean(tf.boolean_mask(tf.pow(x_decoded - x,2), mask))\n",
        "    #reconst_loss=original_dim*objectives.mse(x,x_bar)\n",
        "    kl_loss= -0.5*K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
        "    return kl_loss + reconst_loss\n",
        "\n",
        "vae.compile(optimizer='adam', loss=vae_loss)\n",
        "\n",
        "print(\"number of training users: \", train_mat.shape[0])\n",
        "\n",
        "\n",
        "def nn_batch_generator(x, y, batch_size, samples_per_epoch):\n",
        "    number_of_batches = samples_per_epoch/batch_size\n",
        "    print(number_of_batches)\n",
        "    counter=0\n",
        "    shuffle_index = np.arange(np.shape(y)[0])\n",
        "    np.random.shuffle(shuffle_index)\n",
        "    x =  x[shuffle_index, :]\n",
        "    y =  y[shuffle_index, :]\n",
        "    while 1:\n",
        "        index_batch = shuffle_index[batch_size*counter:batch_size*(counter+1)]\n",
        "        x_batch = x[index_batch,:].todense()\n",
        "        y_batch = y[index_batch,:].todense()\n",
        "        counter += 1\n",
        "        yield (np.array(x_batch),np.array(y_batch))\n",
        "        if (counter >= number_of_batches):\n",
        "            counter=0\n",
        "\n",
        "\n",
        "weightsPath = \"./weights.hdf5\"\n",
        "checkpointer = ModelCheckpoint(filepath=weightsPath, verbose=1, save_best_only=True)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n",
        "\n",
        "# sending complete training data and shuffle flag will shuffle so that each user comes atleast once in training because of multiple epochs\n",
        "vae.fit_generator(nn_batch_generator(x_train, x_train, batch_size, 36774), samples_per_epoch=36774, nb_epoch=nb_epochs, \n",
        "    validation_data=(x_val, x_val), callbacks=[checkpointer, reduce_lr, plot_losses])\n",
        "\n",
        "print(\"training losses over epochs\")\n",
        "print(history.losses)\n",
        "\n",
        "print(\"validation losses over epochs\")\n",
        "print(history.val_losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VbIkjd9QLKu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weightsPath = \"./weights.hdf5\"\n",
        "vae.load_weights(weightsPath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJwHzPngQOT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = Model(x, z_mean)\n",
        "x_train_encoded = encoder.predict(x_train, batch_size=batch_size) \n",
        "print(x_train_encoded.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GzuYbfqQRcJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualizing user embeddings\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from bhtsne import tsne\n",
        "\n",
        "kmeans = KMeans(n_clusters=10, random_state=0).fit(x_train_encoded)\n",
        "x_train_cluster_labels = kmeans.labels_\n",
        "\n",
        "x_train_2_embedded = tsne(x_train_encoded.astype('float64'))\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.scatter(x_train_2_embedded[:, 0], x_train_2_embedded[:, 1], c=x_train_cluster_labels)\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBBwkwVmQSFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}